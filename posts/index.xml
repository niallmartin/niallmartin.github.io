<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Niall Martin</title>
    <link>https://niallmartin.io/posts/</link>
    <description>Recent content in Posts on Niall Martin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 03 Feb 2020 19:30:32 +0000</lastBuildDate>
    
	<atom:link href="https://niallmartin.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Formative Machine Learning Research Papers</title>
      <link>https://niallmartin.io/posts/formative-machine-learning-research-papers/</link>
      <pubDate>Mon, 03 Feb 2020 19:30:32 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/formative-machine-learning-research-papers/</guid>
      <description>Formative Machine Learning Research Papers    Year Last Name First Name Title Link     1943 McCullough Warren A logical calculus of the ideas immanent in nervous activity Link   1943 McCullough Warren A logical calculus of the ideas immanent in nervous activity Link   1949 Hebb Donald The Organization of Behaviour Link   1950 Turing Alan Computing Machinery &amp;amp; Intelligence Link   1955 McCarthy John A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence Link   1958 Rosenblatt Frank The Perceptron: A probabalistic model for information storage and organization in the brain Link   1960 Fraser A.</description>
    </item>
    
    <item>
      <title>Machine Learning Notebook</title>
      <link>https://niallmartin.io/posts/machine-learning-notebook/</link>
      <pubDate>Sat, 01 Feb 2020 18:00:32 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/machine-learning-notebook/</guid>
      <description>Machine Learning Notebook I have a terrible memory. But thing that I find particularly helpful when trying to remember conepts is an ongoing journal of terms. I&#39;ve traditionally use a moleskin for this task, but have decided to switch to using this blog.
In that spirit, what follows is a live, ever evolving list of ML concepts, links and papers.
Optimisers Term used to describe algorithms that minimise (or maximise) the objective function.</description>
    </item>
    
    <item>
      <title>[Data Analysis] Dublin Property Trends</title>
      <link>https://niallmartin.io/posts/data-analysis-dublin-property-trends/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/data-analysis-dublin-property-trends/</guid>
      <description>Analyse and Map Property Price Trends Looking for a house can be stressful. Where to go, what to spend, where the competition is. There&#39;s a lot of choice, but little analysis of the market as a whole.
As such, I spent the day reviewing data from the Property Price Register - a live dataset of all residential properties purchased in Ireland since the 1st January 2010. With information relating to the date of sale, sale price, and the address, this dataset provided me with enough base information to obtain the geospatial coordinates for all house sales using the Google Maps API.</description>
    </item>
    
    <item>
      <title>[Colab Notebook] Keras &amp; LSTM models to Predict Stock Prices</title>
      <link>https://niallmartin.io/posts/colab-notebook-keras-lstm-models-to-predict-stock-prices/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/colab-notebook-keras-lstm-models-to-predict-stock-prices/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Analysing and Predicting Stock Market Trends</title>
      <link>https://niallmartin.io/posts/analysing-and-predicting-stock-market-trends/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/analysing-and-predicting-stock-market-trends/</guid>
      <description>Aim This notebook aims to provide a brief outline the results from a stock-market analysis, demonstrating how LSTM RNN models can be implemented with Keras and Tensorflow. It&#39;s important to note that all results discussed in this post are intended to be high-level, though the reader is encouraged to review this colab notebook for a more detailed analysis and a discussion of the underlying code.
Notes on the data Data was downloaded from Yahoo finance, which includes the following features:</description>
    </item>
    
    <item>
      <title>Ongoing List of my Favourite Data Science Blogs</title>
      <link>https://niallmartin.io/posts/ongoing-list-of-my-favourite-data-science-blogs/</link>
      <pubDate>Tue, 15 Oct 2019 15:15:12 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/ongoing-list-of-my-favourite-data-science-blogs/</guid>
      <description>&amp;ldquo;Life is really simple, but we insist on making it complicated&amp;rdquo; ~ Confucius
Simple is harder than complex. And this&#39;s particularly true of academic research and ML models. I&#39;m always on the lookout for resources that aim to simply describe statistical concepts and machine learning in an simple manner. Those who can do so truly understand the topic.
Here&#39;s an ongoign list of blogs and resources that I love the most.</description>
    </item>
    
    <item>
      <title>How to Start Learning Deep Learning</title>
      <link>https://niallmartin.io/posts/how-to-start-learning-deep-learning/</link>
      <pubDate>Wed, 23 May 2018 10:58:32 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/how-to-start-learning-deep-learning/</guid>
      <description>The Basics Due to the recent achievements of artificial neural networks across many different tasks (such as face recognition, object detection and Go), deep learning has become extremely popular. This post aims to be a starting point for those interested in learning more about it.
If you already have a basic understanding of linear algebra, calculus, probability and programming:
I recommend starting with Stanford’s CS231n. The course notes are comprehensive and written well.</description>
    </item>
    
    <item>
      <title>Introductory Resources for Data Science</title>
      <link>https://niallmartin.io/posts/introductory-resources-for-data-science/</link>
      <pubDate>Wed, 24 May 2017 10:58:32 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/introductory-resources-for-data-science/</guid>
      <description>Getting started in data science can be a daunting task. The area is broad, with little guidance on where one topic start and the next ends. Because of that, I&#39;ve pulled together this list of resources that particularly helped me when I was starting out.
I&#39;ve broken the links into the following four categories, each of which distinguishes between the different skills required by data scientists:
 Data Analytics - Involves feature engineering and statistical tests.</description>
    </item>
    
    <item>
      <title>The Simpler Derivation of Logistic Regression</title>
      <link>https://niallmartin.io/posts/the-simpler-derivation-of-logistic-regression/</link>
      <pubDate>Wed, 11 Jan 2017 10:58:32 +0000</pubDate>
      
      <guid>https://niallmartin.io/posts/the-simpler-derivation-of-logistic-regression/</guid>
      <description>Main Derivation Logistic regression is one of the most popular ways to fit models for categorical data, especially for binary response data. It is the most important (and probably most used) member of a class of models called generalized linear models. Unlike linear regression, logistic regression can directly predict probabilities (values that are restricted to the (0,1) interval); furthermore, those probabilities are well-calibrated when compared to the probabilities predicted by some other classifiers, such as Naive Bayes.</description>
    </item>
    
    <item>
      <title>Classification Model to Predict Loan Default</title>
      <link>https://niallmartin.io/posts/classification-model-to-predict-loan-default/</link>
      <pubDate>Fri, 19 Aug 2016 00:00:00 +0100</pubDate>
      
      <guid>https://niallmartin.io/posts/classification-model-to-predict-loan-default/</guid>
      <description>As part of my Insight project, I choose to help Zidisha improve their default detection system. But wait, who is Zidisha?
Zidisha&amp;hellip; Zidisha is a non-profit startup that allows entrepreneurs in developing countries to request credit. Using a crowdsourcing financial model, individuals like Bineta are able to raise the necessary funds to grow their business. This approach allows entrepreneurs to develop sustainable businesses, and provides jobs for additional members in the community.</description>
    </item>
    
    <item>
      <title>Building Classification Models</title>
      <link>https://niallmartin.io/posts/building-classification-models/</link>
      <pubDate>Thu, 11 Aug 2016 00:00:00 +0100</pubDate>
      
      <guid>https://niallmartin.io/posts/building-classification-models/</guid>
      <description>Building Building on information presented in my previous post, this articles describes how bagging and boosted can be used to build a classification model. The data is available from Kaggle, and represents the financial transactions from two hundred thousand individuals (each with 800 features).
Using this dataset, I set about building a loan-default model. The overall pipeline for this project was split into a few stages, all of which are described below.</description>
    </item>
    
  </channel>
</rss>